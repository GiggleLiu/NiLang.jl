<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bessel function · NiLang.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NiLang.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../why/">What and Why</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../../tutorial/">My first NiLang program</a></li><li><a class="tocitem" href="../port_zygote/">How to port NiLang to Zygote</a></li><li><a class="tocitem" href="../port_chainrules/">How to port NiLang to ChainRules</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../fib/">Computing Fibonacci Numbers</a></li><li><a class="tocitem" href="../pyramid/">Pyramid example</a></li><li class="is-active"><a class="tocitem" href>Bessel function</a><ul class="internal"><li><a class="tocitem" href="#CUDA-programming"><span>CUDA programming</span></a></li><li><a class="tocitem" href="#Benchmark"><span>Benchmark</span></a></li></ul></li><li><a class="tocitem" href="../sparse/">Sparse matrices</a></li><li><a class="tocitem" href="../lognumber/">Logarithmic number system</a></li><li><a class="tocitem" href="../unitary/">Unitary matrix operations without allocation</a></li><li><a class="tocitem" href="../nice/">NICE network</a></li><li><a class="tocitem" href="../realnvp/">RealNVP network</a></li><li><a class="tocitem" href="../qr/">A simple QR decomposition</a></li><li><a class="tocitem" href="../boxmuller/">Box-Muller method to Generate normal distribution</a></li></ul></li><li><span class="tocitem">API &amp; Manual</span><ul><li><a class="tocitem" href="../../instructions/">Instruction Reference</a></li><li><a class="tocitem" href="../../extend/">How to extend</a></li><li><a class="tocitem" href="../sharedwrite/">The shared write problem on GPU</a></li><li><a class="tocitem" href="../../api/">API Manual</a></li><li><a class="tocitem" href="../../faq/">-</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Bessel function</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bessel function</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/GiggleLiu/NiLang.jl/blob/master/examples/besselj.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Bessel-function"><a class="docs-heading-anchor" href="#Bessel-function">Bessel function</a><a id="Bessel-function-1"></a><a class="docs-heading-anchor-permalink" href="#Bessel-function" title="Permalink"></a></h1><p>An Bessel function of the first kind of order <span>$\nu$</span> can be computed using Taylor expansion</p><p class="math-container">\[    J_\nu(z) = \sum\limits_{n=0}^{\infty} \frac{(z/2)^\nu}{\Gamma(k+1)\Gamma(k+\nu+1)} (-z^2/4)^{n}\]</p><p>where <span>$\Gamma(n) = (n-1)!$</span> is the Gamma function. One can compute the accumulated item iteratively as <span>$s_n = -\frac{z^2}{4} s_{n-1}$</span>.</p><pre><code class="language-julia hljs">using NiLang, NiLang.AD
using ForwardDiff: Dual</code></pre><p>Since we need to use logarithmic numbers to handle the sequential mutiplication. Let&#39;s first add patch about the conversion between <code>ULogarithmic</code> and <code>Dual</code> number.</p><pre><code class="language-julia hljs">function Base.convert(::Type{Dual{T,V,N}}, x::ULogarithmic) where {T,V,N}
	Dual{T,V,N}(exp(x.log))
end

@i function ibesselj(y!::T, ν, z::T; atol=1e-8) where T
	if z == 0
		if v == 0
			out! += 1
		end
	else
		@routine @invcheckoff begin
			k ← 0
			@ones ULogarithmic{T} lz halfz halfz_power_2 s
			@zeros T out_anc
			lz *= convert(z)
			halfz *= lz / 2
			halfz_power_2 *= halfz ^ 2
			# s *= (z/2)^ν/ factorial(ν)
			s *= halfz ^ ν
			for i=1:ν
				s /= i
			end
			out_anc += convert(s)
			@from k==0 while s.log &gt; -25 # upto precision e^-25
				k += 1
				# s *= 1 / k / (k+ν) * (z/2)^2
				s *= halfz_power_2 / (@const k*(k+ν))
				if k%2 == 0
					out_anc += convert(s)
				else
					out_anc -= convert(s)
				end
			end
		end
		y! += out_anc
		~@routine
	end
end</code></pre><p>To obtain gradients, one call <strong>Grad(ibesselj)</strong></p><pre><code class="language-julia hljs">y, x = 0.0, 1.0
Grad(ibesselj)(Val(1), y, 2, x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(Val{1}(), GVar(0.0, 1.0), 2, GVar(1.0, 0.21024361588126536))</code></pre><p>Here, <strong>Grad(ibesselj)</strong> is a callable instance of type <strong>Grad{typeof(ibesselj)}}</strong>. The first parameter <code>Val(1)</code> indicates the first argument is the loss.</p><p>To obtain second order gradients, one can Feed dual numbers to this gradient function.</p><pre><code class="language-julia hljs">_, hxy, _, hxx = Grad(ibesselj)(Val(1), Dual(y, zero(y)), 2, Dual(x, one(x)))
println(&quot;The hessian dy^2/dx^2 is $(grad(hxx).partials[1])&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">The hessian dy^2/dx^2 is 0.13446683891656322</code></pre><p>Here, the gradient field is a Dual number, it has a field partials that stores the derivative with respect to <code>x</code>. This is the Hessian that we need.</p><h2 id="CUDA-programming"><a class="docs-heading-anchor" href="#CUDA-programming">CUDA programming</a><a id="CUDA-programming-1"></a><a class="docs-heading-anchor-permalink" href="#CUDA-programming" title="Permalink"></a></h2><p>The AD in NiLang avoids most heap allocation, so that it is able to execute on a GPU device We suggest using <a href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstraction</a>, it provides compatibility between CPU and GPU. To execute the above function on GPU, we need only 11 lines of code.</p><pre><code class="language-julia hljs">using CUDA, GPUArrays, KernelAbstractions

@i @kernel function bessel_kernel(out!, v, z)
    @invcheckoff i ← @index(Global)
    ibesselj(out![i], v, z[i])
    @invcheckoff i → @index(Global)
end</code></pre><p>We have a macro support to KernelAbstraction in NiLang. So it is possible to launch directly like.</p><pre><code class="language-julia hljs">@i function befunc(out!, v::Integer, z)
    @launchkernel CUDADevice() 256 length(out!) bessel_kernel(out!, v, z)
end</code></pre><p>It is equivalent to call</p><pre><code class="language-julia hljs">(~bessel_kernel)(CUDADevice(), 256)(out!, v, z; ndrange=length(out!))</code></pre><p>But it will execute the job eagerly for you. We will consider better support in the future.</p><p>Except it is reversible</p><pre><code class="language-julia hljs">julia&gt; @code_reverse @launchkernel CUDA() 256 length(out!) bessel_kernel(out!, v, z)
:(#= REPL[4]:1 =# @launchkernel CUDA() 256 length(out!) (~bessel_kernel)(out!, v, z))</code></pre><p>To test this function, we first define input parameters <code>a</code> and output <code>out!</code></p><pre><code class="language-julia hljs">a = CuArray(rand(128))
out! = CuArray(zeros(128))</code></pre><p>We wrap the output with a randomly initialized gradient field, suppose we get the gradients from a virtual loss function. Also, we need to initialize an empty gradient field for elements in input cuda tensor <code>a</code>.</p><pre><code class="language-julia hljs">out! = ibesselj(out!, 2, GVar.(a))[1]
out_g! = GVar.(out!, CuArray(randn(128)))</code></pre><p>Call the inverse program, the multiple dispatch will drive you to the goal.</p><pre><code class="language-julia hljs">(~ibesselj)(out_g!, 2, GVar.(a))</code></pre><p>You will get CUDA arrays with <code>GVar</code> elements as output, their gradient fields are what you want. Cheers! Now you have a adjoint mode differentiable CUDA kernel.</p><h2 id="Benchmark"><a class="docs-heading-anchor" href="#Benchmark">Benchmark</a><a id="Benchmark-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmark" title="Permalink"></a></h2><p>We have different source to souce automatic differention implementations of the first type Bessel function <span>$J_2(1.0)$</span> benchmarked and show the results below.</p><table><tr><th style="text-align: right">Package</th><th style="text-align: right">Tangent/Adjoint</th><th style="text-align: right"><span>$T_{\rm min}$</span>/ns</th><th style="text-align: right">Space/KB</th></tr><tr><td style="text-align: right">Julia</td><td style="text-align: right">-</td><td style="text-align: right">22</td><td style="text-align: right">0</td></tr><tr><td style="text-align: right">NiLang</td><td style="text-align: right">-</td><td style="text-align: right">59</td><td style="text-align: right">0</td></tr><tr><td style="text-align: right">ForwardDiff</td><td style="text-align: right">Tangent</td><td style="text-align: right">35</td><td style="text-align: right">0</td></tr><tr><td style="text-align: right">Manual</td><td style="text-align: right">Adjoint</td><td style="text-align: right">83</td><td style="text-align: right">0</td></tr><tr><td style="text-align: right">NiLang.AD</td><td style="text-align: right">Adjoint</td><td style="text-align: right">213</td><td style="text-align: right">0</td></tr><tr><td style="text-align: right">NiLang.AD (GPU)</td><td style="text-align: right">Adjoint</td><td style="text-align: right">1.4</td><td style="text-align: right">0</td></tr><tr><td style="text-align: right">Zygote</td><td style="text-align: right">Adjoint</td><td style="text-align: right">31201</td><td style="text-align: right">13.47</td></tr><tr><td style="text-align: right">Tapenade</td><td style="text-align: right">Adjoint</td><td style="text-align: right">?</td><td style="text-align: right">?</td></tr></table><p>Julia is the CPU time used for running the irreversible forward program, is the baseline of benchmarking. NiLang is the reversible implementation, it is 2.7 times slower than its irreversible counterpart. Here, we have remove the reversibility check. ForwardDiff gives the best performance because it is designed for functions with single input. It is even faster than manually derived gradients</p><p class="math-container">\[\frac{\partial J_{\nu}(z)}{\partial z} = \frac{J_{\nu-1} - J_{\nu+1}}{2}\]</p><p>NiLang.AD is the reversible differential programming implementation, it considers only the backward pass. The benchmark of its GPU version is estimated on Nvidia Titan V by broadcasting the gradient function on CUDA array of size <span>$2^17$</span> and take average. The Zygote benchmark considers both forward pass and backward pass. Tapenade is not yet ready.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../pyramid/">« Pyramid example</a><a class="docs-footer-nextpage" href="../sparse/">Sparse matrices »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.15 on <span class="colophon-date" title="Tuesday 22 March 2022 20:51">Tuesday 22 March 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
